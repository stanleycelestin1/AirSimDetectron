{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objection Detection in Airsim with Detectron \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform inference real time on airsim simulation that is running.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "\n",
    "from caffe2.python import workspace\n",
    "\n",
    "from detectron.utils.colormap import colormap\n",
    "import detectron.utils.env as envu\n",
    "import detectron.utils.keypoints as keypoint_utils\n",
    "\n",
    "from detectron.core.config import assert_and_infer_cfg\n",
    "from detectron.core.config import cfg\n",
    "from detectron.core.config import merge_cfg_from_file\n",
    "from detectron.utils.io import cache_url\n",
    "from detectron.utils.logging import setup_logging\n",
    "from detectron.utils.timer import Timer\n",
    "import detectron.core.test_engine as infer_engine\n",
    "import detectron.datasets.dummy_datasets as dummy_datasets\n",
    "import detectron.utils.c2 as c2_utils\n",
    "import detectron.utils.vis as vis_utils\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import airsim\n",
    "#import matplotlib\n",
    "envu.set_up_matplotlib()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first two lines in the next box is reponsible for connecting to the Car client from Airsim. \n",
    "You should see a confirmation message: \"Connected!\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "Found Detectron ops lib: /home/t-stcele/anaconda2/lib/libcaffe2_detectron_ops_gpu.so\n"
     ]
    }
   ],
   "source": [
    "# connect to the AirSim simulator\n",
    "client = airsim.CarClient()\n",
    "client.confirmConnection()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "_GRAY = (218, 227, 218)\n",
    "_GREEN = (18, 127, 15)\n",
    "_WHITE = (255, 255, 255)\n",
    "\n",
    "\n",
    "c2_utils.import_detectron_ops()\n",
    "\n",
    "# OpenCL may be enabled by default in OpenCV3; disable it because it's not\n",
    "# thread safe and causes unwanted GPU memory allocations.\n",
    "cv2.ocl.setUseOpenCL(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next two cell contains a few functions that are adapted from dectron/utils/vis.py\n",
    "\n",
    "Only the vis_image is significantly edited from storing the result image to showing it in real time.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_string(class_index, score, dataset):\n",
    "    class_text = dataset.classes[class_index] if dataset is not None else \\\n",
    "        'id{:d}'.format(class_index)\n",
    "    return class_text + ' {:0.2f}'.format(score).lstrip('0')\n",
    "\n",
    "\n",
    "def kp_connections(keypoints):\n",
    "    kp_lines = [\n",
    "        [keypoints.index('left_eye'), keypoints.index('right_eye')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('right_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('right_eye'), keypoints.index('right_ear')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('left_ear')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],\n",
    "        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],\n",
    "        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],\n",
    "        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('right_knee')],\n",
    "        [keypoints.index('right_knee'), keypoints.index('right_ankle')],\n",
    "        [keypoints.index('left_hip'), keypoints.index('left_knee')],\n",
    "        [keypoints.index('left_knee'), keypoints.index('left_ankle')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('left_hip')],\n",
    "    ]\n",
    "    return kp_lines\n",
    "\n",
    "\n",
    "def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):\n",
    "    \"\"\"Convert from the class boxes/segms/keyps format generated by the testing\n",
    "    code.\n",
    "    \"\"\"\n",
    "    box_list = [b for b in cls_boxes if len(b) > 0]\n",
    "    if len(box_list) > 0:\n",
    "        boxes = np.concatenate(box_list)\n",
    "    else:\n",
    "        boxes = None\n",
    "    if cls_segms is not None:\n",
    "        segms = [s for slist in cls_segms for s in slist]\n",
    "    else:\n",
    "        segms = None\n",
    "    if cls_keyps is not None:\n",
    "        keyps = [k for klist in cls_keyps for k in klist]\n",
    "    else:\n",
    "        keyps = None\n",
    "    classes = []\n",
    "    for j in range(len(cls_boxes)):\n",
    "        classes += [j] * len(cls_boxes[j])\n",
    "    return boxes, segms, keyps, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_image(fig,\n",
    "        im, boxes, segms=None, keypoints=None, thresh=0.9,\n",
    "        kp_thresh=2, dpi=200, box_alpha=0.0, dataset=None, show_class=False):\n",
    "\n",
    "    \"\"\"Visual debugging of detections.\"\"\"\n",
    "\n",
    "    if isinstance(boxes, list):\n",
    "        boxes, segms, keypoints, classes = convert_from_cls_format(\n",
    "            boxes, segms, keypoints)\n",
    "\n",
    "    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:\n",
    "        return\n",
    "\n",
    "    dataset_keypoints, _ = keypoint_utils.get_keypoints()\n",
    "\n",
    "    if segms is not None and len(segms) > 0:\n",
    "        masks = mask_util.decode(segms)\n",
    "\n",
    "    color_list = colormap(rgb=True) / 255\n",
    "\n",
    "    kp_lines = kp_connections(dataset_keypoints)\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]\n",
    "\n",
    "\n",
    "\n",
    "    dpi /=14\n",
    "    fig.set_size_inches(im.shape[1]/dpi , im.shape[0] / dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.axis('off')\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(im)\n",
    "\n",
    "    # Display in largest to smallest order to reduce occlusion\n",
    "    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    sorted_inds = np.argsort(-areas)\n",
    "    mask_color_id = 0\n",
    "    for i in sorted_inds:\n",
    "        bbox = boxes[i, :4]\n",
    "        score = boxes[i, -1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "\n",
    "        # show box (off by default)\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1],\n",
    "                          fill=False, edgecolor='g',\n",
    "                          linewidth=0.5, alpha=box_alpha))\n",
    "\n",
    "        if show_class:\n",
    "            ax.text(\n",
    "                bbox[0], bbox[1] - 2,\n",
    "                get_class_string(classes[i], score, dataset),\n",
    "                fontsize=30,\n",
    "                family='serif',\n",
    "                bbox=dict(\n",
    "                    facecolor='g', alpha=0.4, pad=0, edgecolor='none'),\n",
    "                color='white')\n",
    "#         print('The class string and score is:', get_class_string(classes[i], score, dataset))\n",
    "        # show mask\n",
    "        if segms is not None and len(segms) > i:\n",
    "            img = np.ones(im.shape)\n",
    "            color_mask = color_list[mask_color_id % len(color_list), 0:3]\n",
    "            mask_color_id += 1\n",
    "\n",
    "            w_ratio = .4\n",
    "            for c in range(3):\n",
    "                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio\n",
    "            for c in range(3):\n",
    "                img[:, :, c] = color_mask[c]\n",
    "            e = masks[:, :, i]\n",
    "\n",
    "            _, contour, hier = cv2.findContours(\n",
    "                e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            for c in contour:\n",
    "                polygon = Polygon(\n",
    "                    c.reshape((-1, 2)),\n",
    "                    fill=True, facecolor=color_mask,\n",
    "                    edgecolor='w', linewidth=1.2,\n",
    "                    alpha=0.5)\n",
    "                ax.add_patch(polygon)\n",
    "\n",
    "        # show keypoints\n",
    "        if keypoints is not None and len(keypoints) > i:\n",
    "            kps = keypoints[i]\n",
    "            plt.autoscale(False)\n",
    "            for l in range(len(kp_lines)):\n",
    "                i1 = kp_lines[l][0]\n",
    "                i2 = kp_lines[l][1]\n",
    "                if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:\n",
    "                    x = [kps[0, i1], kps[0, i2]]\n",
    "                    y = [kps[1, i1], kps[1, i2]]\n",
    "                    line = plt.plot(x, y)\n",
    "                    plt.setp(line, color=colors[l], linewidth=1.0, alpha=0.7)\n",
    "                if kps[2, i1] > kp_thresh:\n",
    "                    plt.plot(\n",
    "                        kps[0, i1], kps[1, i1], '.', color=colors[l],\n",
    "                        markersize=3.0, alpha=0.7)\n",
    "\n",
    "                if kps[2, i2] > kp_thresh:\n",
    "                    plt.plot(\n",
    "                        kps[0, i2], kps[1, i2], '.', color=colors[l],\n",
    "                        markersize=3.0, alpha=0.7)\n",
    "\n",
    "            # add mid shoulder / mid hip for better visualization\n",
    "            mid_shoulder = (\n",
    "                kps[:2, dataset_keypoints.index('right_shoulder')] +\n",
    "                kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0\n",
    "            sc_mid_shoulder = np.minimum(\n",
    "                kps[2, dataset_keypoints.index('right_shoulder')],\n",
    "                kps[2, dataset_keypoints.index('left_shoulder')])\n",
    "            mid_hip = (\n",
    "                kps[:2, dataset_keypoints.index('right_hip')] +\n",
    "                kps[:2, dataset_keypoints.index('left_hip')]) / 2.0\n",
    "            sc_mid_hip = np.minimum(\n",
    "                kps[2, dataset_keypoints.index('right_hip')],\n",
    "                kps[2, dataset_keypoints.index('left_hip')])\n",
    "            if (sc_mid_shoulder > kp_thresh and\n",
    "                    kps[2, dataset_keypoints.index('nose')] > kp_thresh):\n",
    "                x = [mid_shoulder[0], kps[0, dataset_keypoints.index('nose')]]\n",
    "                y = [mid_shoulder[1], kps[1, dataset_keypoints.index('nose')]]\n",
    "                line = plt.plot(x, y)\n",
    "                plt.setp(\n",
    "                    line, color=colors[len(kp_lines)], linewidth=1.0, alpha=0.7)\n",
    "            if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:\n",
    "                x = [mid_shoulder[0], mid_hip[0]]\n",
    "                y = [mid_shoulder[1], mid_hip[1]]\n",
    "                line = plt.plot(x, y)\n",
    "                plt.setp(\n",
    "                    line, color=colors[len(kp_lines) + 1], linewidth=1.0,\n",
    "                    alpha=0.7)\n",
    "\n",
    "\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<logging.Logger at 0x7f7f614c0850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n",
    "setup_logging(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom dictionary to hold the arguments that idealy would be passed when running airsim_infer_simple.\n",
    "\n",
    "Intialise a object to hold the configuration and weight links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDict(dict):\n",
    "    pass\n",
    "\n",
    "\n",
    "args         = MyDict()\n",
    "args.cfg     = '../../configs/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml'\n",
    "args.weights = 'https://s3-us-west-2.amazonaws.com/detectron/35861858/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml.02_32_51.SgT4y1cO/output/train/coco_2014_train:coco_2014_valminusminival/generalized_rcnn/model_final.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING cnn.py:  25: [====DEPRECATE WARNING====]: you are creating an object from CNNModelHelper class which will be deprecated soon. Please use ModelHelper object with brew module. For more information, please refer to caffe2.ai and python/brew.py, python/brew_test.py for more information.\n",
      "INFO net.py:  59: Loading weights from: /tmp/detectron-download-cache/35861858/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml.02_32_51.SgT4y1cO/output/train/coco_2014_train:coco_2014_valminusminival/generalized_rcnn/model_final.pkl\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "merge_cfg_from_file(args.cfg)\n",
    "cfg.NUM_GPUS = 1\n",
    "args.weights = cache_url(args.weights, cfg.DOWNLOAD_CACHE)\n",
    "assert_and_infer_cfg(cache_urls=False)\n",
    "\n",
    "assert not cfg.MODEL.RPN_ONLY, \\\n",
    "    'RPN models are not supported'\n",
    "assert not cfg.TEST.PRECOMPUTED_PROPOSALS, \\\n",
    "    'Models that require precomputed proposals are not supported'\n",
    "\n",
    "model = infer_engine.initialize_model_from_cfg(args.weights)\n",
    "dummy_coco_dataset = dummy_datasets.get_coco_dataset()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO <ipython-input-12-f95cd069c451>:   6:  \\ Note: inference on the first image will be slower than the rest (caches and auto-tuning need to warm up)\n"
     ]
    }
   ],
   "source": [
    " # set timer so that conversion will run for a set time\n",
    "minutes = 6\n",
    "endTime = time.time() + minutes * 60\n",
    "\n",
    "logger.info(\n",
    "    ' \\ Note: inference on the first image will be slower than the '\n",
    "    'rest (caches and auto-tuning need to warm up)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " while time.time() < endTime:\n",
    "        print('.',end=\"\")\n",
    "        timers = defaultdict(Timer)\n",
    "        t = time.time()\n",
    "        \n",
    "        raw = client.simGetImages([airsim.ImageRequest(\"1\", airsim.ImageType.Scene, False, False)])\n",
    "\n",
    "        im = np.fromstring(raw[0].image_data_uint8, dtype=np.uint8)  # get numpy array\n",
    "        im = im.reshape(raw[0].height, raw[0].width, 4)\n",
    "\n",
    "        b, g, r, a = np.rollaxis(im, axis=-1)\n",
    "\n",
    "        im = np.dstack([r, g, b])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with c2_utils.NamedCudaScope(0):\n",
    "            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(\n",
    "                model, im, None, timers=timers\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        vis_image(fig,\n",
    "            im[:, :, ::-1],  # BGR -> RGB for visualization\n",
    "            cls_boxes,\n",
    "            cls_segms,\n",
    "            cls_keyps,\n",
    "            dataset=dummy_coco_dataset,\n",
    "            box_alpha=0.3,\n",
    "            show_class=True,\n",
    "            thresh=0.7,\n",
    "            kp_thresh=2\n",
    "        )\n",
    "    \n",
    "        print('Time: {:.3f}s'.format(time.time() - t),end=\"|--|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
